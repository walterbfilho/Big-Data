DOCUMENTO DE ARQUITETURA - PIPELINE DE BIG DATA
An√°lise Preditiva de Churn em Telecomunica√ß√µes

==========================================
INFORMA√á√ïES DO PROJETO
==========================================

Projeto: An√°lise Preditiva de Churn em Telecomunica√ß√µes
Disciplina: Fundamentos de Big Data
Data: 13/10/2024
Equipe: Leonardo Azevedo e [Outros Membros]

==========================================
ARQUITETURA DO PIPELINE DE DADOS
==========================================

O projeto implementa uma arquitetura Medallion com 3 camadas:

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    PIPELINE DE DADOS                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   üì• BRONZE  ‚îÇ  -->  ‚îÇ   üîß SILVER  ‚îÇ  -->  ‚îÇ   üèÜ GOLD    ‚îÇ
‚îÇ  Dados Brutos‚îÇ       ‚îÇTransformados ‚îÇ       ‚îÇ   Insights   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

CAMADA BRONZE (Ingest√£o):
- Fonte: Dataset Telco Customer Churn (Kaggle)
- Registros: 7.043 clientes
- Formato: CSV original
- Localiza√ß√£o: /dados/bronze/
- Arquivos: telco_churn_raw.csv, relatorio_ingestao.txt

CAMADA SILVER (Transforma√ß√£o):
- Processamento: Limpeza, valida√ß√£o, engenharia de features
- Features criadas: 15+ vari√°veis derivadas
- Formato: CSV + Parquet (compress√£o ~60%)
- Localiza√ß√£o: /dados/silver/
- Arquivos: telco_churn_transformed.csv/.parquet, relatorio_transformacao.txt

CAMADA GOLD (An√°lise):
- Visualiza√ß√µes: 3 gr√°ficos principais
- Datasets agregados: M√©tricas por contrato, perfil de risco
- Insights: Recomenda√ß√µes estrat√©gicas
- Localiza√ß√£o: /dados/gold/
- Arquivos: 6 arquivos anal√≠ticos + relat√≥rio final

==========================================
TECNOLOGIAS UTILIZADAS
==========================================

AMBIENTE DE DESENVOLVIMENTO:
- Google Colab (plataforma principal - sem custos)
- Python 3.x (linguagem de programa√ß√£o)
- Jupyter Notebooks (desenvolvimento)

BIBLIOTECAS DE PROCESSAMENTO:
- Pandas: Manipula√ß√£o e transforma√ß√£o de dados
- NumPy: Opera√ß√µes num√©ricas vetorizadas
- PyArrow: Leitura/escrita de arquivos Parquet
- Scikit-learn: Normaliza√ß√£o e pr√©-processamento

BIBLIOTECAS DE VISUALIZA√á√ÉO:
- Matplotlib: Gr√°ficos est√°ticos
- Seaborn: Visualiza√ß√µes estat√≠sticas

FORMATO DE ARMAZENAMENTO:
- CSV: Dados brutos e intermedi√°rios
- Parquet: Dados transformados (compress√£o ~60%)

==========================================
JUSTIFICATIVA DAS ESCOLHAS TECNOL√ìGICAS
==========================================

GOOGLE COLAB:
- Vantagens: Gratuito, ambiente pr√©-configurado, f√°cil compartilhamento
- Desvantagens: Limita√ß√µes de recursos, depend√™ncia de internet
- Justificativa: Ideal para projetos acad√™micos sem custos

PYTHON + PANDAS:
- Vantagens: Sintaxe intuitiva, bibliotecas robustas, comunidade ativa
- Desvantagens: Performance inferior a linguagens compiladas
- Justificativa: Padr√£o da ind√∫stria para an√°lise de dados

ARQUITETURA MEDALLION:
- Vantagens: Organiza√ß√£o clara, rastreabilidade, escalabilidade
- Desvantagens: Complexidade inicial maior
- Justificativa: Melhores pr√°ticas da ind√∫stria

PARQUET:
- Vantagens: Compress√£o eficiente, schema evolution, performance
- Desvantagens: Menos compatibilidade com ferramentas legadas
- Justificativa: Formato otimizado para Big Data

==========================================
DIVIS√ÉO DE TAREFAS DA EQUIPE
==========================================

MEMBER 1 - LEONARDO AZEVEDO:
- Responsabilidade: Ingest√£o e Documenta√ß√£o
- Tarefas:
  * Implementa√ß√£o do notebook 01_ingestao.ipynb
  * Implementa√ß√£o do notebook 02_transformacao.ipynb
  * Cria√ß√£o da estrutura de pastas
  * Documenta√ß√£o t√©cnica e README.md
  * Cria√ß√£o do checklist_av1.md

MEMBER 2 - WALTER ANDR√â DE S√Å BARRETO FILHO:
- Responsabilidade: Transforma√ß√£o e Engenharia de Features
- Tarefas:
  * Cria√ß√£o do Reposit√≥rio
  * Implementa√ß√£o do notebook 02_transformacao.ipynb
  * Cria√ß√£o de features derivadas
  * Normaliza√ß√£o e padroniza√ß√£o dos dados
  * Valida√ß√£o de qualidade

MEMBER 3 - MARIANA BELO:
- Responsabilidade: An√°lise e Visualiza√ß√£o
- Tarefas:
  * Implementa√ß√£o do notebook 03_analise_visualizacao.ipynb
  * Cria√ß√£o de visualiza√ß√µes
  * Gera√ß√£o de insights e m√©tricas
  * Relat√≥rio final

==========================================
FLUXO DE DADOS DETALHADO
==========================================

ETAPA 1 - INGEST√ÉO:
1. Download/verifica√ß√£o do dataset Telco Customer Churn
2. Carregamento dos dados brutos (7.043 registros)
3. Valida√ß√£o inicial (duplicatas, tipos de dados)
4. Salvamento na camada Bronze
5. Gera√ß√£o de relat√≥rio de ingest√£o

ETAPA 2 - TRANSFORMA√á√ÉO:
1. Carregamento dos dados da camada Bronze
2. Limpeza e tratamento de valores ausentes
3. Engenharia de features (15+ vari√°veis criadas)
4. Codifica√ß√£o de vari√°veis categ√≥ricas
5. Normaliza√ß√£o MinMaxScaler
6. Salvamento na camada Silver (CSV + Parquet)
7. Gera√ß√£o de relat√≥rio de transforma√ß√£o

ETAPA 3 - AN√ÅLISE:
1. Carregamento dos dados da camada Silver
2. An√°lise explorat√≥ria de dados
3. Cria√ß√£o de visualiza√ß√µes (3 gr√°ficos)
4. Gera√ß√£o de datasets agregados
5. C√°lculo de m√©tricas de churn
6. Salvamento na camada Gold
7. Gera√ß√£o de relat√≥rio final com insights

==========================================
M√âTRICAS E KPIs
==========================================

M√âTRICAS T√âCNICAS:
- Registros processados: 7.043 clientes
- Features criadas: 15+ vari√°veis derivadas
- Taxa de compress√£o Parquet: ~60%
- Tempo de processamento: < 5 minutos
- Linhas de c√≥digo: ~1.200 linhas

M√âTRICAS DE NEG√ìCIO:
- Taxa geral de churn: 26.5%
- Contratos mensais: ~42% de churn
- Contratos anuais: ~11% de churn
- Contratos bienais: ~3% de churn
- Clientes novos (0-12m): Alto risco

==========================================
PRINCIPAIS DESCOBERTAS
==========================================

1. TIPO DE CONTRATO √â O FATOR MAIS CR√çTICO:
   - Diferen√ßa de 39 pontos percentuais entre mensal e bienal
   - Contratos longos reduzem significativamente o churn

2. TEMPO DE PERMAN√äNCIA IMPACTA SIGNIFICATIVAMENTE:
   - Primeiros 12 meses s√£o cr√≠ticos para reten√ß√£o
   - Clientes antigos (37m+) t√™m baixo risco de churn

3. PERFIL DE ALTO RISCO IDENTIFICADO:
   - Contrato mensal + tenure <= 12 meses
   - Taxa de churn elevada neste segmento

==========================================
RECOMENDA√á√ïES ESTRAT√âGICAS
==========================================

1. MIGRA√á√ÉO PARA CONTRATOS LONGOS:
   - Oferecer desconto de 15-20% em contratos anuais
   - Criar programa de fidelidade para contratos bienais

2. ONBOARDING INTENSIVO:
   - Acompanhamento especial nos primeiros 90 dias
   - Suporte proativo para clientes novos

3. BUNDLING DE SERVI√áOS:
   - Pacotes com 4+ servi√ßos para aumentar reten√ß√£o
   - Descontos progressivos por n√∫mero de servi√ßos

4. PROGRAMA DE SEGURAN√áA:
   - Trial gratuito de 30 dias para servi√ßos de seguran√ßa
   - Educa√ß√£o sobre benef√≠cios de prote√ß√£o

==========================================
PR√ìXIMAS ETAPAS (AV2)
==========================================

MELHORIAS PLANEJADAS:
- Implementar modelo de Machine Learning preditivo
- Criar dashboard interativo com Streamlit
- Desenvolver API para scoring em tempo real
- Sistema de alertas automatizados
- A/B Testing de estrat√©gias de reten√ß√£o

TECNOLOGIAS AVAN√áADAS (FUTURO):
- Apache Spark para processamento distribu√≠do
- Apache Kafka para streaming de dados
- MLflow para versionamento de modelos
- Docker para containeriza√ß√£o
- AWS/GCP para infraestrutura em nuvem

==========================================
CONCLUS√ÉO
==========================================

O pipeline de Big Data implementado demonstra com sucesso:

1. ARQUITETURA ROBUSTA:
   - Implementa√ß√£o da arquitetura Medallion
   - Separa√ß√£o clara de responsabilidades
   - Rastreabilidade completa dos dados

2. PROCESSAMENTO EFICIENTE:
   - Tratamento de 7.043 registros
   - Cria√ß√£o de 15+ features derivadas
   - Compress√£o de 60% com Parquet

3. INSIGHTS ACION√ÅVEIS:
   - Identifica√ß√£o de fatores cr√≠ticos de churn
   - Recomenda√ß√µes estrat√©gicas espec√≠ficas
   - M√©tricas de sucesso definidas

4. DOCUMENTA√á√ÉO COMPLETA:
   - C√≥digo bem comentado e organizado
   - Relat√≥rios t√©cnicos detalhados
   - Arquitetura documentada

O projeto est√° pronto para a AV1 e preparado para evolu√ß√µes na AV2.

==========================================
Pipeline de Big Data - Fundamentos de Big Data
Equipe: Leonardo Azevedo e [Outros Membros]
Data: 13/10/2024
==========================================
